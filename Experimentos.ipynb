{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd101e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import math, subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "from os import listdir, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0ce3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"Resultados\",\n",
    "    \"Data\"\n",
    "]\n",
    "def crearPaths(paths=paths):\n",
    "    for p in paths:    \n",
    "        if not path.exists(f\"{os.getcwd()}/{p}\"):\n",
    "            os.mkdir(f\"{os.getcwd()}/{p}\")\n",
    "crearPaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683f6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correr experimentos (ver como hay que modificar con lo de usar python y c++ juntos)\n",
    "def correr_experimento(archivo_training, archivo_testing, archivo_salida, k, metodo, nitter, epsilon, alfa):\n",
    "        \n",
    "    # Crear proceso para ejecutar el codigo.\n",
    "    if metodo == '0':\n",
    "        process = subprocess.Popen([\"./build/tp2\", archivo_training, archivo_testing, archivo_salida, k, metodo], stderr=subprocess.PIPE, stdout=subprocess.PIPE, stdin=subprocess.PIPE, universal_newlines = True)\n",
    "    else:\n",
    "        process = subprocess.Popen([\"./build/tp2\", archivo_training, archivo_testing, archivo_salida, k, metodo, nitter, epsilon, alfa], stderr=subprocess.PIPE, stdout=subprocess.PIPE, stdin=subprocess.PIPE, universal_newlines = True)\n",
    "\n",
    "    # Poner la instancia en la entrada estandar y leer salida de STDERR con el tiempo de ejecución.\n",
    "    stdout, stderr = process.communicate() # communicate() devuelve una tupla (stdout, stderr)\n",
    "\n",
    "    tiempo_de_ejecucion = str.splitlines(stderr)[0]\n",
    "    #print(clog)\n",
    "\n",
    "    # Correr experimento.\n",
    "    exit_code = process.wait()\n",
    "\n",
    "    # Verificar que el proceso no fallo.\n",
    "    if exit_code != 0: raise(F\"Hubo un error en la experimentacion con el metodo {'kNN' if metodo == 0 else 'PCA'} con los parámetros {archivo_training}, {archivo_testing}, k:{k} {', nitter:'+nitter if metodo == 1 else ''} {', epsilon:'+epsilon if metodo == 1 else ''} {', alfa:'+alfa if metodo == 1 else ''}.\")\n",
    "    return float(tiempo_de_ejecucion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd0a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experimento:\n",
    "    def __init__(self, trainingDataset, testingDataset, outputFile, metodo, vecinos, num_iter, alfa, epsilon):\n",
    "        self.trainingDataset = trainingDataset\n",
    "        self.testingDataset = testingDataset\n",
    "        self.outputFile = outputFile\n",
    "        self.metodo = metodo\n",
    "        self.vecinos = vecinos\n",
    "        self.num_iter = num_iter\n",
    "        self.alfa = alfa\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def display(self):\n",
    "        display(f\"Archivo De Entrenamiento: {self.trainingDataset}\")\n",
    "        display(f\"Archivo De Prueba: {self.testingDataset}\")\n",
    "        display(f\"Archivo De Salida: {self.outputFile}\")\n",
    "        display(f\"Metodo: {self.metodo}\")\n",
    "        display(f\"Vecinos: {self.vecinos}\")\n",
    "        display(f\"Numero De Iteraciones: {self.num_iter}\")\n",
    "        display(f\"Alfa: {self.alfa}\")\n",
    "        display(f\"Epsilon: {self.epsilon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3060cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceDataset(n):\n",
    "    dataset = pd.read_csv(\"train.csv\")\n",
    "    reducedDataset = resample(dataset, replace = False, n_samples = n)\n",
    "    return reducedDataset\n",
    "\n",
    "\n",
    "def splitDataset(dataset, testSize=0.3): #default 70-30 como el fernet\n",
    "    train, test = train_test_split(dataset, test_size=testSize);\n",
    "    train.to_csv(path_or_buf=\"Data/random_train.csv\", index=False)\n",
    "    test.to_csv(path_or_buf=\"Data/random_validate.csv\", index=False)\n",
    "    return[train, test]\n",
    "\n",
    "\n",
    "#obsoleta\n",
    "def k_foldDataset(dataset, k):\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    fold_indices = kf.split(X=dataset)\n",
    "    for key, indices in enumerate(fold_indices, 1):\n",
    "        train_indices = indices[0]\n",
    "        #test_indices = indices[1]\n",
    "        fold_train_dataset = dataset.filter(items=train_indices, axis=0) \n",
    "        #fold_test_dataset = dataset.filter(items=test_indices, axis=0) \n",
    "        fold_train_dataset.to_csv(path_or_buf=f\"Data/{k}_fold-{key}.csv\", index=False)\n",
    "        #fold_test_dataset.to_csv(path_or_buf=f\"Data/{k}_fold-{key}-test.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b8efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si se corre dos veces sobre la misma cantidad de folds pisa los archivos\n",
    "def prepareDataSet(size, folds):\n",
    "    reducedDataset = reduceDataset(size);\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    fold_splits = kf.split(X=reducedDataset)\n",
    "\n",
    "    for key, split in enumerate(fold_splits, 1):\n",
    "        training_indices = split[0]\n",
    "        validate_indices = split[1]\n",
    "\n",
    "        trainDataset = reducedDataset.iloc[training_indices]\n",
    "        validateDataset = reducedDataset.iloc[validate_indices]\n",
    "        \n",
    "        trainDataset.to_csv(path_or_buf=f\"Data/{folds}_fold-SET-{key}-train.csv\", index=False)\n",
    "        validateDataset.to_csv(path_or_buf=f\"Data/{folds}_fold-SET-{key}-validate.csv\", index=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db7e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar experimentos para busqueda de mejor k de knn sin pca en un 5-fold del dataset reducido\n",
    "def generarExperimentosKnn(folds, maxK, step):\n",
    "    knnExp = []\n",
    "    for key in range(1,folds+1):\n",
    "        knnExp += [ Experimento(\n",
    "            f\"./Data/{folds}_fold-SET-{key}-train.csv\",\n",
    "            f\"./Data/{folds}_fold-SET-{key}-validate.csv\",\n",
    "            f\"./resultados/{folds}_fold-SET-{key}-{k}-vecinos-resultados.csv\",\n",
    "            \"0\",\n",
    "            f\"{k}\",\n",
    "            None,\n",
    "            None,\n",
    "            None\n",
    "        ) for k in range(1, maxK+1, step)]\n",
    "    return knnExp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "332f8183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLabelsFrom(archivo):\n",
    "    dataset = pd.read_csv(archivo);\n",
    "    labels = dataset[dataset.columns[0]]\n",
    "    return labels\n",
    "\n",
    "\n",
    "def calculateAccuracy(sourceFile, resultsFile):\n",
    "    expectedLabels = extractLabelsFrom(sourceFile)\n",
    "    resultLabels = extractLabelsFrom(resultsFile)\n",
    "    \n",
    "    hits = 0\n",
    "    for index, result in enumerate(resultLabels):\n",
    "        if result == expectedLabels[index]:\n",
    "            hits += 1\n",
    "    accuracy = hits/len(expectedLabels)\n",
    "    return accuracy\n",
    "\n",
    "#potencialmente obsoleto\n",
    "def averageAccuracy(vecinos, x_fold):\n",
    "    sourceFiles = [f\"./Data/{x_fold}_fold-SET-{set}-validate.csv\" for set in range(1, x_fold+1)]\n",
    "    resultFiles = [f\"./resultados/{x_fold}_fold-SET-{set}-{vecinos}-vecinos-resultados.csv\" for set in range(1, x_fold+1)]\n",
    "    \n",
    "    accuracies = []\n",
    "    for index, srcFile in enumerate(sourceFiles):\n",
    "        accuracies.append(calculateAccuracy(srcFile, resultFiles[index]))\n",
    "    \n",
    "    return np.median(accuracies)\n",
    "\n",
    "def precisionAndRecallMulticase(sourceFile, resultsFile):\n",
    "    expectedLabels = extractLabelsFrom(sourceFile)\n",
    "    resultLabels = extractLabelsFrom(resultsFile)\n",
    "\n",
    "\n",
    "    truePositives = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "    falsePositives = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "    falseNegatives = np.array([0,0,0,0,0,0,0,0,0,0])\n",
    "    for index, result in enumerate(resultLabels):\n",
    "        if result == expectedLabels[index]:\n",
    "            truePositives[int(result)] += 1\n",
    "        elif result != expectedLabels[index]:\n",
    "            falsePositives[int(result)] += 1\n",
    "            falseNegatives[int(expectedLabels[index])] += 1\n",
    "\n",
    "    precisions = np.around(np.divide(truePositives, (truePositives + falsePositives)), 4)\n",
    "    recalls = np.around(np.divide(truePositives, (truePositives + falseNegatives)), 4)\n",
    "\n",
    "    return [precisions, recalls]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbbe8002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experimento: 5 de 5 info:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Archivo De Entrenamiento: ./Data/5_fold-SET-5-train.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Archivo De Prueba: ./Data/5_fold-SET-5-validate.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Archivo De Salida: ./resultados/5_fold-SET-5-1-vecinos-resultados.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Metodo: 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Vecinos: 1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero De Iteraciones: None'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Alfa: None'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epsilon: None'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def correr_experimentos(experimentos):\n",
    "    if not path.exists(\"./resultados/resultado.csv\"):\n",
    "        columnas=[\"SetEntrenamiento\", \"SetTesting\", \"Resultados\", \"Método\", \"Vecinos\", \"Numero de iteraciones\", \"Alfa\", \"Epsilon\", \"Tiempo\", \"Accuracy\", \"p0\", \"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\", \"p7\",\"p8\", \"p9\", \"r0\", \"r1\", \"r2\", \"r3\", \"r4\", \"r5\", \"r6\", \"r7\",\"r8\", \"r9\"]\n",
    "        df_resultado = pd.DataFrame([], columns=columnas);\n",
    "    else:\n",
    "        df_resultado = pd.read_csv(\"./resultados/resultado.csv\")\n",
    "\n",
    "    filas=[]\n",
    "    iteraciones = 1 #PONER EN 5 PARA LA CORRIDA OFICIAL\n",
    "    for index, experimento in enumerate(experimentos):\n",
    "        clear_output(wait=True)\n",
    "        display(f\"Experimento: {index+1} de {len(experimentos)} info:\")\n",
    "        experimento.display()\n",
    "        \n",
    "        tiempos = []\n",
    "        for i in range(0, iteraciones):\n",
    "            tiempo = correr_experimento(\n",
    "                experimento.trainingDataset, \n",
    "                experimento.testingDataset, \n",
    "                experimento.outputFile, \n",
    "                experimento.vecinos, \n",
    "                experimento.metodo, \n",
    "                experimento.num_iter, \n",
    "                experimento.epsilon, \n",
    "                experimento.alfa\n",
    "            )\n",
    "            tiempos.append(tiempo)\n",
    "                \n",
    "        tiempo_promedio = np.median(tiempos)\n",
    "\n",
    "        accuracy = calculateAccuracy(experimento.testingDataset, experimento.outputFile)\n",
    "        [precisions, recalls] = precisionAndRecallMulticase(experimento.testingDataset, experimento.outputFile)\n",
    "        os.remove(experimento.outputFile) #Una vez calculadas las métricas no nos sirven creo, y asi ahorramos espacio\n",
    "\n",
    "        if experimento.metodo == \"0\":\n",
    "            idList = df_resultado.index[(df_resultado[\"SetEntrenamiento\"] == experimento.trainingDataset)\n",
    "                                        & (df_resultado[\"SetTesting\"] == experimento.testingDataset) \n",
    "                                        & (df_resultado[\"Resultados\"] == experimento.outputFile)\n",
    "                                        & (df_resultado[\"Método\"] == int(experimento.metodo))\n",
    "                                        & (df_resultado[\"Vecinos\"] == int(experimento.vecinos))\n",
    "                                        ].tolist()\n",
    "        else:\n",
    "            idList = df_resultado.index[(df_resultado[\"SetEntrenamiento\"] == experimento.trainingDataset)\n",
    "                                        & (df_resultado[\"SetTesting\"] == experimento.testingDataset) \n",
    "                                        & (df_resultado[\"Resultados\"] == experimento.outputFile)\n",
    "                                        & (df_resultado[\"Método\"] == int(experimento.metodo))\n",
    "                                        & (df_resultado[\"Vecinos\"] == int(experimento.vecinos))\n",
    "                                        & (df_resultado[\"Numero de iteraciones\"] == experimento.num_iter)\n",
    "                                        & (df_resultado[\"Alfa\"] == experimento.alfa)\n",
    "                                        & (df_resultado[\"Epsilon\"] == experimento.epsilon)\n",
    "                                        ].tolist()\n",
    "            \n",
    "\n",
    "        if len(idList) > 1:\n",
    "            print(\"ERROR: Falta filtrar mejor la fila o hay experimentos repetidos\")\n",
    "            break\n",
    "        elif len(idList) == 0:\n",
    "            df_resultado = pd.concat([df_resultado, pd.DataFrame([[experimento.trainingDataset, experimento.testingDataset, experimento.outputFile, experimento.metodo, experimento.vecinos, experimento.num_iter, experimento.alfa, experimento.epsilon] + [None for j in range(22)]], columns=df_resultado.columns)])\n",
    "            if experimento.metodo == \"0\":\n",
    "                idList = df_resultado.index[(df_resultado[\"SetEntrenamiento\"] == experimento.trainingDataset)\n",
    "                                            & (df_resultado[\"SetTesting\"] == experimento.testingDataset) \n",
    "                                            & (df_resultado[\"Resultados\"] == experimento.outputFile)\n",
    "                                            & (df_resultado[\"Método\"] == experimento.metodo)\n",
    "                                            & (df_resultado[\"Vecinos\"] == experimento.vecinos)\n",
    "                                            ].to_list()\n",
    "            else:\n",
    "                idList = df_resultado.index[(df_resultado[\"SetEntrenamiento\"] == experimento.trainingDataset)\n",
    "                                            & (df_resultado[\"SetTesting\"] == experimento.testingDataset) \n",
    "                                            & (df_resultado[\"Resultados\"] == experimento.outputFile)\n",
    "                                            & (df_resultado[\"Método\"] == int(experimento.metodo))\n",
    "                                            & (df_resultado[\"Vecinos\"] == int(experimento.vecinos))\n",
    "                                            & (df_resultado[\"Numero de iteraciones\"] == experimento.num_iter)\n",
    "                                            & (df_resultado[\"Alfa\"] == experimento.alfa)\n",
    "                                            & (df_resultado[\"Epsilon\"] == experimento.epsilon)\n",
    "                                            ].tolist()\n",
    "\n",
    "        id = idList[0]\n",
    "        \n",
    "        df_resultado.loc[id, 'Tiempo'] = tiempo_promedio\n",
    "        df_resultado.loc[id, 'Accuracy'] = accuracy\n",
    "        for j in range(10):\n",
    "            df_resultado.loc[id, f'p{j}'] = precisions[j]\n",
    "            df_resultado.loc[id, f'r{j}'] = recalls[j]\n",
    "\n",
    "    df_resultado.to_csv(\"./resultados/resultado.csv\", index=False, header=True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "experimentos = []\n",
    "\n",
    "prepareDataSet(10000, folds)\n",
    "experimentos = generarExperimentosKnn(folds, 2001, 50)\n",
    "correr_experimentos(experimentos)\n",
    "\n",
    "prepareDataSet(42000, folds)\n",
    "experimentos = generarExperimentosKnn(folds, 51, 5)\n",
    "correr_experimentos(experimentos)\n",
    "#experimentos += generarExperimentosKnn(folds, 6, 1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "889c0b3ca612a67eaa1dc5740a27885fb9965c2660345635b57c83d6520625b4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
